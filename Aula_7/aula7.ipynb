{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fcn-train1.py\n",
    "#Treina rede fcn para segmentacao semantica de eliret\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "from tensorflow import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "import sys; import cv2; import numpy as np; import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impHistoria(history):\n",
    "    print(history.history.keys())\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss'); plt.ylabel('loss'); plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def leCsv(nomeDir,nomeArq):\n",
    "    print(\"Lendo: \",nomeArq); arq=open(os.path.join(nomeDir,nomeArq),\"r\")\n",
    "    lines=arq.readlines(); arq.close(); n=len(lines)\n",
    "    #print(lines)\n",
    "    nl,nc = 32,32\n",
    "    AX=np.empty((n,nl,nc),dtype='uint8'); AY=np.empty((n,nl,nc),dtype='uint8')\n",
    "    i=0\n",
    "    for linha in lines:\n",
    "        linha=linha.strip('\\n'); linha=linha.split(';')\n",
    "        AX[i]=cv2.imread(os.path.join(nomeDir,linha[0]),cv2.IMREAD_GRAYSCALE)\n",
    "        AY[i]=cv2.imread(os.path.join(nomeDir,linha[1]),cv2.IMREAD_GRAYSCALE)\n",
    "        i=i+1\n",
    "    ax= np.float32(AX)/255.0; ay= np.float32(AY)/255.0 #Entre 0 e +1\n",
    "    ax = ax.reshape(n, nl, nc, 1); ay = ay.reshape(n, nl, nc, 1)\n",
    "    return ax, ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdDir = \"Dados\"\n",
    "ax, ay = leCsv(bdDir,\"treino.csv\")\n",
    "vx, vy = leCsv(bdDir,\"valida.csv\")\n",
    "qx, qy = leCsv(bdDir,\"teste.csv\")\n",
    "outDir = \".\"; os.chdir(outDir)\n",
    "nl,nc = 32,32; input_shape = (nl,nc,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size = (32,32,1)):\n",
    "    n=40\n",
    "    inputs = Input(input_size) #32x32\n",
    "    conv2 = Conv2D(n, 5, activation = 'relu', padding = 'same' )(inputs)\n",
    "    conv2 = Conv2D(n, 5, activation = 'relu', padding = 'same' )(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #16x16\n",
    "    \n",
    "    conv3 = Conv2D(2*n, 5, activation = 'relu', padding = 'same' )(pool2) #16x16\n",
    "    conv3 = Conv2D(2*n, 5, activation = 'relu', padding = 'same' )(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3) #8x8\n",
    "    \n",
    "    conv4 = Conv2D(4*n, 5, activation = 'relu', padding = 'same' )(pool3) #8x8\n",
    "    conv4 = Conv2D(4*n, 5, activation = 'relu', padding = 'same' )(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4) #4x4\n",
    "    \n",
    "    conv5 = Conv2D(8*n, 5, activation = 'relu', padding = 'same' )(pool4) #4x4\n",
    "    conv5 = Conv2D(8*n, 5, activation = 'relu', padding = 'same' )(conv5) #4x4\n",
    "    \n",
    "    up6 = Conv2D(4*n, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv5)) #8x8\n",
    "    merge6 = concatenate([conv4,up6], axis = 3) #8x8\n",
    "    conv6 = Conv2D(4*n, 5, activation = 'relu', padding = 'same' )(merge6)\n",
    "    conv6 = Conv2D(4*n, 5, activation = 'relu', padding = 'same' )(conv6) #8x8\n",
    "    \n",
    "    up7 = Conv2D(2*n, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6)) #16x16\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(2*n, 5, activation = 'relu', padding = 'same' )(merge7)\n",
    "    conv7 = Conv2D(2*n, 5, activation = 'relu', padding = 'same' )(conv7) #16x16\n",
    "    \n",
    "    up8 = Conv2D(n, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7)) #32x32\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(n, 5, activation = 'relu', padding = 'same' )(merge8)\n",
    "    conv8 = Conv2D(n, 5, activation = 'relu', padding = 'same' )(conv8) #32x32\n",
    "    \n",
    "    conv9 = Conv2D(1, 1, activation = 'sigmoid', padding = 'same' )(conv8) #32x32\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = conv9)\n",
    "    model.compile(optimizer = Adam(learning_rate=1e-3), loss = 'mean_squared_error')\n",
    "    from keras.utils import plot_model\n",
    "    plot_model(model, to_file='unet-train1.png', show_shapes=True)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20; epochs = 1000\n",
    "model=unet()\n",
    "opt=keras.optimizers.Adam()\n",
    "model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "history=model.fit(ax, ay, batch_size=batch_size, epochs=epochs, verbose=0, validation_data=(vx,vy))\n",
    "impHistoria(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(ax, ay, verbose=0); print('Training loss:', score)\n",
    "score = model.evaluate(vx, vy, verbose=0); print('Validation loss:', score)\n",
    "score = model.evaluate(qx, qy, verbose=0); print('Test loss:', score)\n",
    "model.save('fcn-train1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
