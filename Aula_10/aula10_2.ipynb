{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet_transf.py\n",
    "#Faz transfer learning usando ResNet50.\n",
    "#https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import numpy as np;\n",
    "from tensorflow import keras \n",
    "import keras.backend as K\n",
    "from keras import optimizers, callbacks, regularizers\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "from keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando o arquivo feiCorCrop.zip para diretorio default d:\\Faculdade\\PSI3472\\Aula_10\n",
      "Descompactando arquivos novos de feiCorCrop.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Descarregar segm_eliret.zip\n",
    "url='http://www.lps.usp.br/hae/apostila/feiCorCrop.zip'\n",
    "import os; nomeArq=os.path.split(url)[1]\n",
    "if not os.path.exists(nomeArq):\n",
    "  print(\"Baixando o arquivo\",nomeArq,\"para diretorio default\",os.getcwd())\n",
    "  os.system(\"wget -nc -U 'Firefox/50.0' \"+url)\n",
    "else:\n",
    "  print(\"O arquivo\",nomeArq,\"ja existe no diretorio default\",os.getcwd())\n",
    "print(\"Descompactando arquivos novos de\",nomeArq)  \n",
    "os.system(\"unzip -u \"+nomeArq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leCsv(nomeDir, nomeArq, nl=0, nc=0):\n",
    "    st=os.path.join(nomeDir,nomeArq);\n",
    "    arq=open(st,\"rt\"); lines=arq.readlines(); arq.close(); n=len(lines)\n",
    "    \n",
    "    linhas_separadas=[]\n",
    "    for linha in lines:\n",
    "        linha=linha.strip('\\n'); linha=linha.split(';'); linhas_separadas.append(linha)\n",
    "    \n",
    "    ay=np.empty((n),dtype='float32'); ax=np.empty((n,nl,nc,3),dtype='float32')\n",
    "    for i in range(len(linhas_separadas)):\n",
    "        linha=linhas_separadas[i]\n",
    "        img_path=os.path.join(nomeDir,linha[0])\n",
    "        t = load_img(img_path, target_size=(nl,nc))\n",
    "        x = img_to_array(t)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        ax[i] = preprocess_input(x)\n",
    "        ay[i] = np.float32(linha[1]) #0=m ou 1=f\n",
    "    return ax, ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomeprog=\"resnet_transf\"\n",
    "#Original: 280x200, redimensionado: 224x224\n",
    "num_classes=2; nl=224; nc=224\n",
    "batch_size = 10\n",
    "diretorioBd=\"Dados\"\n",
    "ax, ay = leCsv(diretorioBd,\"treino.csv\", nl=nl, nc=nc); #200 imagens\n",
    "qx, qy = leCsv(diretorioBd,\"teste.csv\", nl=nl, nc=nc); #100 imagens\n",
    "vx, vy = leCsv(diretorioBd,\"valida.csv\", nl=nl, nc=nc); #100 imagens\n",
    "ay = keras.utils.to_categorical(ay, num_classes)\n",
    "qy = keras.utils.to_categorical(qy, num_classes)\n",
    "vy = keras.utils.to_categorical(vy, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelevaluate(model,ax,ay,vx,vy,qx,qy):\n",
    "    score = model.evaluate(ax, ay, verbose=0); print('Training loss:', score)\n",
    "    score = model.evaluate(vx, vy, verbose=0); print('Validation loss:', score)\n",
    "    score = model.evaluate(qx, qy, verbose=0); print('Test loss:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "def load_all_models(n_models):\n",
    "\tall_models = list()\n",
    "\tfor i in range(n_models):\n",
    "\t\t# define filename for this ensemble\n",
    "\t\tfilename = 'models/resnet_transf' + str(i) + '.h5'\n",
    "\t\t# load model from file\n",
    "\t\tmodel = load_model(filename)\n",
    "\t\t# add to list of members\n",
    "\t\tall_models.append(model)\n",
    "\t\tprint('>loaded %s' % filename)\n",
    "\treturn all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded models/resnet_transf0.h5\n",
      ">loaded models/resnet_transf1.h5\n",
      ">loaded models/resnet_transf2.h5\n",
      ">loaded models/resnet_transf3.h5\n",
      ">loaded models/resnet_transf4.h5\n",
      "Loaded 5 models\n"
     ]
    }
   ],
   "source": [
    "members = load_all_models(5)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: [0.09653446823358536, 0.9900000095367432]\n",
      "Validation loss: [0.9457689523696899, 0.9599999785423279]\n",
      "Test loss: [0.15690910816192627, 0.9800000190734863]\n",
      "Training loss: [0.028125612065196037, 0.9950000047683716]\n",
      "Validation loss: [0.7118646502494812, 0.949999988079071]\n",
      "Test loss: [0.08846602588891983, 0.9900000095367432]\n",
      "Training loss: [6.098863741499372e-05, 1.0]\n",
      "Validation loss: [1.0286810398101807, 0.9300000071525574]\n",
      "Test loss: [0.011690777726471424, 0.9900000095367432]\n",
      "Training loss: [0.05391884222626686, 0.9900000095367432]\n",
      "Validation loss: [2.0524823665618896, 0.9100000262260437]\n",
      "Test loss: [0.003270217450335622, 1.0]\n",
      "Training loss: [0.23480074107646942, 0.9850000143051147]\n",
      "Validation loss: [0.4384792447090149, 0.9599999785423279]\n",
      "Test loss: [0.062085919082164764, 0.9700000286102295]\n"
     ]
    }
   ],
   "source": [
    "for model in members:\n",
    "\tmodelevaluate(model,ax,ay,vx,vy,qx,qy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an ensemble prediction for multi-class classification\n",
    "def ensemble_predictions(members, testX):\n",
    "\t# make predictions\n",
    "\tyhats = [model.predict(testX) for model in members]\n",
    "\tyhats = np.array(yhats)\n",
    "\t# sum across ensemble members\n",
    "\tsummed = np.sum(yhats, axis=0)\n",
    "\t# argmax across classes\n",
    "\tresult = np.argmax(summed, axis=1)\n",
    "\treturn result\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "def evaluate_n_members(members, n_members, testX, testy):\n",
    "\t# select a subset of members\n",
    "\tsubset = members[:n_members]\n",
    "\tprint(len(subset))\n",
    "\t# make prediction\n",
    "\tyhat = ensemble_predictions(subset, testX)\n",
    "\t# calculate accuracy\n",
    "\treturn accuracy_score(testy, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4/4 [==============================] - 7s 1s/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Faculdade\\PSI3472\\Aula_10\\aula10.ipynb Célula: 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, n_members\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \tscore \u001b[39m=\u001b[39m evaluate_n_members(members, i, qx, qy)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \t\u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m> \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m score)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \tscores\u001b[39m.\u001b[39mappend(score)\n",
      "\u001b[1;32md:\\Faculdade\\PSI3472\\Aula_10\\aula10.ipynb Célula: 10\u001b[0m in \u001b[0;36mevaluate_n_members\u001b[1;34m(members, n_members, testX, testy)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m yhat \u001b[39m=\u001b[39m ensemble_predictions(subset, testX)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# calculate accuracy\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Faculdade/PSI3472/Aula_10/aula10.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(testy, yhat)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "n_members = 6\n",
    "scores = list()\n",
    "for i in range(1, n_members+1):\n",
    "\tscore = evaluate_n_members(members, i, qx, qy)\n",
    "\tprint('> %.3f' % score)\n",
    "\tscores.append(score)\n",
    "# plot score vs number of ensemble members\n",
    "x_axis = [i for i in range(1, n_members+1)]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis, scores)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9be826744cc5714b462ad0c8de88bfa6f016a48973c6317b9546595d1685cabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
